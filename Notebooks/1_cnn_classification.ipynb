{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aba390d9",
   "metadata": {},
   "source": [
    "# üß† Projet Deep Learning ‚Äî Classification des Cellules Sanguines Canc√©reuses (PyTorch)\n",
    "\n",
    "## üìå 1. Contexte du Projet\n",
    "Vous √™tes un d√©veloppeur IA junior au sein d‚Äôun laboratoire biom√©dical sp√©cialis√© en imagerie m√©dicale.\n",
    "Objectif : Automatiser l‚Äôanalyse d‚Äôimages m√©dicales li√©es √† deux pathologies critiques :\n",
    "- D√©tection de **tumeurs c√©r√©brales** (object detection √† partir d‚ÄôIRM),\n",
    "- Classification de **cellules sanguines canc√©reuses** (leuc√©mies) √† partir de frottis sanguins.\n",
    "\n",
    "Cette premi√®re partie se concentre sur la **classification des cellules sanguines canc√©reuses avec PyTorch**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d31dee6",
   "metadata": {},
   "source": [
    "## üßæ 2. Importation des Biblioth√®ques N√©cessaires\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609de3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8190bf28",
   "metadata": {},
   "source": [
    "## üìÇ 3. Chargement des Images & V√©rification des Extensions\n",
    "\n",
    "- Extensions autoris√©es : `.jpeg`, `.jpg`, `.png`, `.bmp`\n",
    "- Suppression des fichiers invalides\n",
    "- Gestion des erreurs via `try-except`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b9a952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a41fd2f3",
   "metadata": {},
   "source": [
    "## üîé 4. Exploration des Classes du Dataset\n",
    "- Liste des dossiers (classes)\n",
    "- Nombre d‚Äôimages par classe (`countplot`)\n",
    "- Affichage d‚Äôun √©chantillon d‚Äôimages par classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e084cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ef6b8d8",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è 5. Division du Dataset en **Train / Validation / Test**\n",
    "- R√©partition : **70% / 15% / 15%**\n",
    "- V√©rification du nombre d‚Äôimages par dossier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c01ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    images, labels,\n",
    "    test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "x_val, x_test, y_val, y_test = train_test_split(\n",
    "    x_test, y_test,\n",
    "    test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "base_path = r\"C:\\Users\\issam\\OneDrive\\Desktop\\Cancers-sanguins-Tumeurs-c-r-brales-via-Transfer-Learning\\Data\\Processed\\Blood_Cells_Cancer\"\n",
    "train_path = os.path.join(base_path, \"Train\")\n",
    "val_path = os.path.join(base_path, \"Validation\")\n",
    "test_path = os.path.join(base_path, \"Test\")\n",
    "\n",
    "for path in [train_path, val_path, test_path]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def copy_images_to_folder(image_paths, labels, destination_path):\n",
    "    for img_path, label in zip(image_paths, labels):\n",
    "        class_folder = os.path.join(destination_path, label)\n",
    "        os.makedirs(class_folder, exist_ok=True)\n",
    "        \n",
    "        img_name = os.path.basename(img_path)\n",
    "        dest_path = os.path.join(class_folder, img_name)\n",
    "        \n",
    "        try:\n",
    "            shutil.copy2(img_path, dest_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la copie de {img_path}: {e}\")\n",
    "\n",
    "copy_images_to_folder(x_train, y_train, train_path)\n",
    "\n",
    "copy_images_to_folder(x_val, y_val, val_path)\n",
    "\n",
    "copy_images_to_folder(x_test, y_test, test_path)\n",
    "\n",
    "print(\"Repartition par classe :\")\n",
    "for dataset_name, dataset_path in [(\"Train\", train_path), (\"Validation\", val_path), (\"Test\", test_path)]:\n",
    "    print(f\"\\n{dataset_name}:\")\n",
    "    if os.path.exists(dataset_path):\n",
    "        classes = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "        for class_name in sorted(classes):\n",
    "            class_path = os.path.join(dataset_path, class_name)\n",
    "            num_images = len([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))])\n",
    "            print(f\"   - {class_name}: {num_images} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa5b329",
   "metadata": {},
   "source": [
    "## üîÑ 6. Data Augmentation (Seulement sur Train)\n",
    "- Transformations : `blur`, `noise`, `flip`\n",
    "- Objectif : √©quilibrer les classes et augmenter la robustesse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db60e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def add_noise(img, noise_level=20):\n",
    "    arr = np.array(img)\n",
    "    noise = np.random.randint(-noise_level, noise_level, arr.shape, dtype='int16')\n",
    "    noisy_arr = np.clip(arr.astype('int16') + noise, 0, 255).astype('uint8')\n",
    "    return Image.fromarray(noisy_arr)\n",
    "\n",
    "def augment_image(img_path, save_dir, augmentations):\n",
    "    img = Image.open(img_path)\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    ext = os.path.splitext(img_path)[1]\n",
    "    aug_count = 0\n",
    "\n",
    "    if 'blur' in augmentations:\n",
    "        blurred = img.filter(ImageFilter.GaussianBlur(radius=2))\n",
    "        blurred.save(os.path.join(save_dir, f\"{base_name}_blur{ext}\"))\n",
    "        aug_count += 1\n",
    "\n",
    "    if 'noise' in augmentations:\n",
    "        noisy = add_noise(img)\n",
    "        noisy.save(os.path.join(save_dir, f\"{base_name}_noise{ext}\"))\n",
    "        aug_count += 1\n",
    "\n",
    "    if 'flip' in augmentations:\n",
    "        flipped = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        flipped.save(os.path.join(save_dir, f\"{base_name}_flip{ext}\"))\n",
    "        aug_count += 1\n",
    "\n",
    "    return aug_count\n",
    "\n",
    "for class_name in os.listdir(train_path):\n",
    "    class_dir = os.path.join(train_path, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "    images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
    "    for img_file in images:\n",
    "        img_path = os.path.join(class_dir, img_file)\n",
    "        augment_image(img_path, class_dir, augmentations=['blur', 'noise', 'flip'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c3a628",
   "metadata": {},
   "source": [
    "## üß™ 7. Pr√©paration des Donn√©es avec `ImageFolder` & `Transforms`\n",
    "- Resize\n",
    "- ToTensor\n",
    "- Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3619b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7b5faa3",
   "metadata": {},
   "source": [
    "## üöö 8. Cr√©ation des DataLoaders\n",
    "- Batch loading\n",
    "- Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0951c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "860eb724",
   "metadata": {},
   "source": [
    "## üß† 9. Chargement du Mod√®le Pr√©-entra√Æn√© **GoogLeNet**\n",
    "- Remplacement de la partie **Fully Connected (FC)** par un `nn.Sequential`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db743dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4ef946b",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 10. Configuration de l‚ÄôEntra√Ænement\n",
    "- Learning Rate\n",
    "- Loss Function\n",
    "- Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b47bcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ecb35a6",
   "metadata": {},
   "source": [
    "## üèãÔ∏è 11. Boucle d‚ÄôEntra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c3aff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42cfaa28",
   "metadata": {},
   "source": [
    "\n",
    "## üìä 12. √âvaluation & Test du Mod√®le\n",
    "- Accuracy / Loss\n",
    "- Matrice de confusion (optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a79ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c77e79b",
   "metadata": {},
   "source": [
    "## üíæ 13. Sauvegarde du Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23228f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c20e240e",
   "metadata": {},
   "source": [
    "## ‚úÖ 14. Conclusion & Observations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
