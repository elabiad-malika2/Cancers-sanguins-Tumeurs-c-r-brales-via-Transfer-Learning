{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "013c8e27",
   "metadata": {},
   "source": [
    "# Deuxi√®me partie : D√©tection des tumeurs c√©r√©brales avec YOLOv8\n",
    "\n",
    "Cette partie consiste √† classer les images de tumeurs c√©r√©brales et √† localiser les tumeurs √† l'aide du mod√®le YOLOv8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf9c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports et configuration initiale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9d7b5f",
   "metadata": {},
   "source": [
    "## 1. Afficher un √©chantillon d'images pour chaque classe avec les bo√Ætes englobantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%pip install Pillow\n",
    "from PIL import Image\n",
    "%pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Dossier racine du dataset\n",
    "data_dir = \"../Data/Raw/Data_Brain/Train\"\n",
    "\n",
    "# R√©cup√©rer les noms des classes (dossiers)\n",
    "classes = os.listdir(data_dir)\n",
    "print(\"Classes :\", classes)\n",
    "\n",
    "# Fonction pour convertir les coordonn√©es YOLO en coordonn√©es d'image\n",
    "def yolo_to_box(x_center, y_center, width, height, img_width, img_height):\n",
    "    x_min = (x_center - width / 2) * img_width\n",
    "    y_min = (y_center - height / 2) * img_height\n",
    "    box_width = width * img_width\n",
    "    box_height = height * img_height\n",
    "    return x_min, y_min, box_width, box_height\n",
    "\n",
    "# Afficher une image pour chaque classe\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, cls in enumerate(classes):\n",
    "    img_dir = os.path.join(data_dir, cls, \"images\")\n",
    "    label_dir = os.path.join(data_dir, cls, \"labels\")\n",
    "\n",
    "    # Prendre la premi√®re image et son label correspondant\n",
    "    img_name = os.listdir(img_dir)[0]\n",
    "    label_name = os.path.splitext(img_name)[0] + \".txt\"\n",
    "\n",
    "    img_path = os.path.join(img_dir, img_name)\n",
    "    label_path = os.path.join(label_dir, label_name)\n",
    "\n",
    "    # Ouvrir l‚Äôimage\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_w, img_h = img.size\n",
    "\n",
    "    # Lire le fichier d‚Äôannotation\n",
    "    with open(label_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Afficher l‚Äôimage\n",
    "    ax = plt.subplot(1, len(classes), i + 1)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(cls)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # Dessiner les bo√Ætes englobantes\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) < 5:\n",
    "            continue\n",
    "        _, x, y, w, h = map(float, parts)\n",
    "        x_min, y_min, bw, bh = yolo_to_box(x, y, w, h, img_w, img_h)\n",
    "        rect = patches.Rectangle(\n",
    "            (x_min, y_min), bw, bh, linewidth=2, edgecolor='red', facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d7f02",
   "metadata": {},
   "source": [
    "## 3. Filtrer et copier les images et labels\n",
    "\n",
    "Pour chaque image :\n",
    "- V√©rifier si un fichier .txt correspondant existe dans le r√©pertoire des labels\n",
    "- Si un label est trouv√© : copier l'image et le label vers le dossier appropri√© (train/valid/test)\n",
    "- Si aucun label n'est trouv√© : afficher un avertissement et sauter l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9321e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# === 1 Dossiers source et sortie ===\n",
    "source_dir = \"../Data/Raw/Data_Brain\"   # Ton dataset\n",
    "output_dir = \"../Data/outputpath\"      # Nouveau dossier de sortie\n",
    "\n",
    "# Cr√©er le dossier de sortie et ses sous-dossiers\n",
    "for sub in [\"images\", \"labels\"]:\n",
    "    for split in [\"Train\", \"Val\"]:\n",
    "        path = os.path.join(output_dir, sub, split)\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "print(\" Dossiers cr√©√©s avec succ√®s !\")\n",
    "\n",
    "# === 2 Extensions d‚Äôimages accept√©es ===\n",
    "valid_ext = (\".jpg\", \".jpeg\", \".png\", \".bmp\")\n",
    "\n",
    "# === 3 Parcourir Train et Val ===\n",
    "for split in [\"Train\", \"Val\"]:\n",
    "    split_path = os.path.join(source_dir, split)\n",
    "\n",
    "    print(f\"\\nüîπ Traitement de {split_path}\")\n",
    "\n",
    "    # Parcourir les classes (Glioma, Meningioma, etc.)\n",
    "    for cls in os.listdir(split_path):\n",
    "        class_path = os.path.join(split_path, cls)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        img_folder = os.path.join(class_path, \"images\")\n",
    "        label_folder = os.path.join(class_path, \"labels\")\n",
    "\n",
    "        if not os.path.exists(img_folder) or not os.path.exists(label_folder):\n",
    "            print(f\"‚ö†Ô∏è {cls} n‚Äôa pas de dossier images ou labels.\")\n",
    "            continue\n",
    "\n",
    "        for img_name in os.listdir(img_folder):\n",
    "            if not img_name.lower().endswith(valid_ext):\n",
    "                continue\n",
    "\n",
    "            label_name = os.path.splitext(img_name)[0] + \".txt\"\n",
    "            img_path = os.path.join(img_folder, img_name)\n",
    "            label_path = os.path.join(label_folder, label_name)\n",
    "\n",
    "            if os.path.exists(label_path):\n",
    "                shutil.copy(img_path, os.path.join(output_dir, \"images\", split, img_name))\n",
    "                shutil.copy(label_path, os.path.join(output_dir, \"labels\", split, label_name))\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Pas de label pour {img_name}\")\n",
    "\n",
    "print(\"\\n‚úÖ Copie termin√©e avec succ√®s ! Seules les images avec labels ont √©t√© copi√©es.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c3854e",
   "metadata": {},
   "source": [
    "## 4. Cr√©er le fichier data.yaml sans augmentations\n",
    "\n",
    "Ce fichier contient :\n",
    "- Les chemins des dossiers d'entra√Ænement, de validation et de test\n",
    "- Le nombre de classes et le nom de chaque classe\n",
    "- Configuration sans augmentations de donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76707542",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyyaml\n",
    "import yaml\n",
    "\n",
    "data_config = {\n",
    "    'train': 'Data/outputpath/images/Train',\n",
    "    'val': 'Data/outputpath/images/Val',\n",
    "    'nc': 4,\n",
    "    'names': ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary'],\n",
    "    'augment': False\n",
    "}\n",
    "\n",
    "with open('../data.yaml', 'w') as file:\n",
    "    yaml.dump(data_config, file)\n",
    "\n",
    "print(\"‚úÖ Fichier data2.yaml cr√©√© avec succ√®s (avec augmentations desactiv√©es) !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b942cb1",
   "metadata": {},
   "source": [
    "## 5. Cr√©er le fichier data2.yaml avec augmentations\n",
    "\n",
    "Ce fichier contient la m√™me structure que data.yaml mais avec des augmentations de donn√©es activ√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10c4597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "data2_config = {\n",
    "    'train': 'Data/outputpath/images/Train',\n",
    "    'val': 'Data/outputpath/images/Val',\n",
    "    'nc': 4,\n",
    "    'names': ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary'],\n",
    "    'augment': True\n",
    "}\n",
    "\n",
    "with open('../data2.yaml', 'w') as file:\n",
    "    yaml.dump(data2_config, file)\n",
    "\n",
    "print(\"‚úÖ Fichier data2.yaml cr√©√© avec succ√®s (avec augmentations activ√©es) !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4385cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf89933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA disponible :\", torch.cuda.is_available())\n",
    "print(\"Nom du GPU :\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Aucun GPU d√©tect√©\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11fc284",
   "metadata": {},
   "source": [
    "## 6. Compter le nombre d'images et d'√©tiquettes\n",
    "\n",
    "Compter les images et labels pr√©sents dans les ensembles d'entra√Ænement et de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567dcf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_images = '../Data/outputpath/images/Train'\n",
    "train_labels = '../Data/outputpath/labels/Train'\n",
    "valid_images = '../Data/outputpath/images/Val'\n",
    "valid_labels = '../Data/outputpath/labels/Val'\n",
    "\n",
    "train_img_count = len([f for f in os.listdir(train_images) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "train_label_count = len([f for f in os.listdir(train_labels) if f.endswith('.txt')])\n",
    "valid_img_count = len([f for f in os.listdir(valid_images) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "valid_label_count = len([f for f in os.listdir(valid_labels) if f.endswith('.txt')])\n",
    "\n",
    "print(f\"tain:\")\n",
    "print(f\"  - Images: {train_img_count}\")\n",
    "print(f\"  - Labels: {train_label_count}\")\n",
    "print(f\"\\nvalidation\")\n",
    "print(f\"  - Images: {valid_img_count}\")\n",
    "print(f\"  - Labels: {valid_label_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d72f00d",
   "metadata": {},
   "source": [
    "## 7. V√©rifier la correspondance images-labels et nettoyer les donn√©es\n",
    "\n",
    "- V√©rifier que chaque image poss√®de un label correspondant\n",
    "- Supprimer les images sans label\n",
    "- Supprimer les labels sans image correspondante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e872f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "datasets = {\n",
    "    'train': {\n",
    "        'images': '../Data/outputpath/images/Train',\n",
    "        'labels': '../Data/outputpath/labels/Train'\n",
    "    },\n",
    "    'valid': {\n",
    "        'images': '../Data/outputpath/images/Val',\n",
    "        'labels': '../Data/outputpath/labels/Val'\n",
    "    }\n",
    "}\n",
    "\n",
    "def verify_and_clean(images_dir, labels_dir):\n",
    "    if not os.path.exists(images_dir) or not os.path.exists(labels_dir):\n",
    "        print(f\"Les r√©pertoires {images_dir} ou {labels_dir} n'existent pas.\")\n",
    "        return\n",
    "    \n",
    "    images = {os.path.splitext(f)[0]: f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.png', '.jpeg'))}\n",
    "    labels = {os.path.splitext(f)[0]: f for f in os.listdir(labels_dir) if f.endswith('.txt')}\n",
    "    \n",
    "    images_removed = 0\n",
    "    labels_removed = 0\n",
    "    \n",
    "    for img_name in list(images.keys()):\n",
    "        if img_name not in labels:\n",
    "            os.remove(os.path.join(images_dir, images[img_name]))\n",
    "            images_removed += 1\n",
    "            print(f\"Image supprim√©e (pas de label): {images[img_name]}\")\n",
    "    \n",
    "    for label_name in list(labels.keys()):\n",
    "        if label_name not in images:\n",
    "            os.remove(os.path.join(labels_dir, labels[label_name]))\n",
    "            labels_removed += 1\n",
    "            print(f\"Label supprim√© (pas d'image): {labels[label_name]}\")\n",
    "    \n",
    "    remaining_count = len(images) - images_removed\n",
    "    print(f\"\\nR√©sum√©: {images_removed} images et {labels_removed} labels supprim√©s\")\n",
    "    print(f\"Paires valides restantes: {remaining_count}\\n\")\n",
    "\n",
    "for dataset_name, paths in datasets.items():\n",
    "    print(f\"=== V√©rification de {dataset_name} ===\")\n",
    "    verify_and_clean(paths['images'], paths['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec62c68",
   "metadata": {},
   "source": [
    "## 8. Entra√Æner le mod√®le YOLOv8\n",
    "\n",
    "Lancer l'entra√Ænement du mod√®le YOLO en d√©finissant les hyperparam√®tres appropri√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8s.pt') \n",
    "\n",
    "model.train(\n",
    "    data='../data.yaml',      \n",
    "    epochs=100,             \n",
    "    batch=-1,\n",
    "    cos_lr=True,\n",
    "    patience=10,                       \n",
    "    device=0,    \n",
    "    save=True,\n",
    "    name='model2_yolov8s'          \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e853e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf59ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8s.pt') \n",
    "\n",
    "model.train(\n",
    "    data='../data2.yaml',      \n",
    "    epochs=100,             \n",
    "    batch=-1,\n",
    "    cos_lr=True,\n",
    "    patience=10,                       \n",
    "    device=0,    \n",
    "    save=True,\n",
    "    name='model_augm'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d4e595",
   "metadata": {},
   "source": [
    "## 9. √âvaluer et tester le mod√®le\n",
    "\n",
    "√âvaluer et tester le mod√®le apr√®s l'entra√Ænement pour mesurer :\n",
    "- Les performances\n",
    "- La pr√©cision\n",
    "- La capacit√© √† g√©n√©raliser sur des donn√©es in√©dites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46507ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "model_path = 'runs/detect/model2_yolov8s/weights/best.pt' \n",
    "model = YOLO(model_path)\n",
    "\n",
    "print(\"√âvaluation du mod√®le sur l'ensemble de validation...\")\n",
    "\n",
    "metrics = model.val(data='../data.yaml', split='val')\n",
    "\n",
    "print(\"\\nM√©triques de performance:\")\n",
    "print(f\"  - mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"  - mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"  - Pr√©cision: {metrics.box.mp:.4f}\")\n",
    "print(f\"  - Rappel (Recall): {metrics.box.mr:.4f}\")\n",
    "\n",
    "print(\"\\n M√©triques par classe:\")\n",
    "class_names = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"  {class_name}:\")\n",
    "    print(f\"    - Pr√©cision: {metrics.box.p[i]:.4f}\")\n",
    "    print(f\"    - Rappel: {metrics.box.r[i]:.4f}\")\n",
    "    print(f\"    - mAP50: {metrics.box.ap50[i]:.4f}\")\n",
    "    print(f\"    - mAP50-95: {metrics.box.ap[i]:.4f}\")\n",
    "\n",
    "print(\"\\n√âvaluation termin√©e!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4926ac87",
   "metadata": {},
   "source": [
    "### 9.2 Tester le mod√®le sur des images de l'ensemble de validation\n",
    "\n",
    "Visualiser les pr√©dictions du mod√®le sur des √©chantillons d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "if 'model' not in locals():\n",
    "    model_path = 'runs/detect/model2_yolov8s/weights/best.pt'\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "val_images_dir = '../Data/outputpath/images/Val'\n",
    "\n",
    "all_images = [f for f in os.listdir(val_images_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "sample_images = random.sample(all_images, min(6, len(all_images)))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "class_names = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "for idx, img_name in enumerate(sample_images):\n",
    "    img_path = os.path.join(val_images_dir, img_name)\n",
    "    \n",
    "    results = model.predict(source=img_path, conf=0.25, verbose=False)\n",
    "    \n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_w, img_h = img.size\n",
    "    \n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].axis('off')\n",
    "    \n",
    "    if len(results) > 0 and results[0].boxes is not None:\n",
    "        boxes = results[0].boxes\n",
    "        \n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes.xyxy[i].cpu().numpy()\n",
    "            conf = boxes.conf[i].cpu().numpy()\n",
    "            cls = int(boxes.cls[i].cpu().numpy())\n",
    "            \n",
    "            x1, y1, x2, y2 = box\n",
    "            width = x2 - x1\n",
    "            height = y2 - y1\n",
    "            \n",
    "            rect = patches.Rectangle(\n",
    "                (x1, y1), width, height,\n",
    "                linewidth=2,\n",
    "                edgecolor=colors[cls],\n",
    "                facecolor='none'\n",
    "            )\n",
    "            axes[idx].add_patch(rect)\n",
    "            \n",
    "            label = f'{class_names[cls]} {conf:.2f}'\n",
    "            axes[idx].text(\n",
    "                x1, y1 - 10,\n",
    "                label,\n",
    "                color='white',\n",
    "                fontsize=10,\n",
    "                bbox=dict(facecolor=colors[cls], alpha=0.7, edgecolor='none', pad=2)\n",
    "            )\n",
    "        \n",
    "        axes[idx].set_title(f'Image: {img_name}', fontsize=10)\n",
    "    else:\n",
    "        axes[idx].set_title(f'Image: {img_name} (Aucune d√©tection)', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Pr√©dictions affich√©es!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef10b058",
   "metadata": {},
   "source": [
    "### 9.3 Matrice de confusion\n",
    "\n",
    "Afficher la matrice de confusion pour analyser les performances du mod√®le par classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c126f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "confusion_matrix_path = 'runs/detect/model2_yolov8s/confusion_matrix.png'\n",
    "\n",
    "if os.path.exists(confusion_matrix_path):\n",
    "    img = Image.open(confusion_matrix_path)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Matrice de confusion', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"Matrice de confusion affich√©e!\")\n",
    "else:\n",
    "    print(f\"La matrice de confusion n'a pas √©t√© trouv√©e √†: {confusion_matrix_path}\")\n",
    "    print(\"Assurez-vous d'avoir ex√©cut√© l'entra√Ænement ou la validation du mod√®le.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7978c5",
   "metadata": {},
   "source": [
    "### 9.4 Courbes de performance (Pr√©cision-Rappel et F1)\n",
    "\n",
    "Afficher les courbes P-R et F1 g√©n√©r√©es pendant l'entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d373bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "results_dir = 'runs/detect/model2_yolov8s'\n",
    "plot_files = {\n",
    "    'Courbe P-R': 'PR_curve.png',\n",
    "    'Courbe F1': 'F1_curve.png',\n",
    "    'Courbe P': 'P_curve.png',\n",
    "    'Courbe R': 'R_curve.png'\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (title, filename) in enumerate(plot_files.items()):\n",
    "    file_path = os.path.join(results_dir, filename)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        img = Image.open(file_path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(title, fontsize=14, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "    else:\n",
    "        axes[idx].text(0.5, 0.5, f'{title}\\nFichier non trouv√©', \n",
    "                      ha='center', va='center', fontsize=12)\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Courbes de performance affich√©es!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306c763d",
   "metadata": {},
   "source": [
    "### 9.5 R√©sultats d'entra√Ænement (Loss et mAP)\n",
    "\n",
    "Afficher l'√©volution des m√©triques pendant l'entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62924b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "results_path = 'runs/detect/model2_yolov8s/results.png'\n",
    "\n",
    "if os.path.exists(results_path):\n",
    "    img = Image.open(results_path)\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('√âvolution des m√©triques pendant l\\'entra√Ænement', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"Graphique des r√©sultats d'entra√Ænement affich√©!\")\n",
    "else:\n",
    "    print(f\"Le fichier des r√©sultats n'a pas √©t√© trouv√© √†: {results_path}\")\n",
    "    print(\"Assurez-vous d'avoir termin√© l'entra√Ænement du mod√®le.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c968dc",
   "metadata": {},
   "source": [
    "## 10. Sauvegarder le mod√®le entra√Æn√©\n",
    "\n",
    "Sauvegarder le mod√®le entra√Æn√© pour une utilisation future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b165f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "best_model_path = 'runs/detect/model2_yolov8s/weights/best.pt'\n",
    "model = YOLO(best_model_path)\n",
    "\n",
    "output_path = '../models/yolomodel.pt'\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "shutil.copy(best_model_path, output_path)\n",
    "\n",
    "print(f\"Mod√®le sauvegard√© avec succ√®s √†: {output_path}\")\n",
    "print(f\"Taille du fichier: {os.path.getsize(output_path) / (1024*1024):.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
