{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "013c8e27",
   "metadata": {},
   "source": [
    "# Deuxième partie : Détection des tumeurs cérébrales avec YOLOv8\n",
    "\n",
    "Cette partie consiste à classer les images de tumeurs cérébrales et à localiser les tumeurs à l'aide du modèle YOLOv8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf9c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports et configuration initiale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9d7b5f",
   "metadata": {},
   "source": [
    "## 1. Afficher un échantillon d'images pour chaque classe avec les boîtes englobantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50ef9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e3d7f02",
   "metadata": {},
   "source": [
    "## 3. Filtrer et copier les images et labels\n",
    "\n",
    "Pour chaque image :\n",
    "- Vérifier si un fichier .txt correspondant existe dans le répertoire des labels\n",
    "- Si un label est trouvé : copier l'image et le label vers le dossier approprié (train/valid/test)\n",
    "- Si aucun label n'est trouvé : afficher un avertissement et sauter l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9321e420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41c3854e",
   "metadata": {},
   "source": [
    "## 4. Créer le fichier data.yaml sans augmentations\n",
    "\n",
    "Ce fichier contient :\n",
    "- Les chemins des dossiers d'entraînement, de validation et de test\n",
    "- Le nombre de classes et le nom de chaque classe\n",
    "- Configuration sans augmentations de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76707542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b942cb1",
   "metadata": {},
   "source": [
    "## 5. Créer le fichier data2.yaml avec augmentations\n",
    "\n",
    "Ce fichier contient la même structure que data.yaml mais avec des augmentations de données activées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10c4597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d11fc284",
   "metadata": {},
   "source": [
    "## 6. Compter le nombre d'images et d'étiquettes\n",
    "\n",
    "Compter les images et labels présents dans les ensembles d'entraînement et de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567dcf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_images = '../Data/Raw/Data_Brain/'\n",
    "train_labels = '../Data/Raw/Data_Brain/'\n",
    "valid_images = '../Data/Raw/Data_Brain/'\n",
    "valid_labels = '../Data/Raw/Data_Brain/'\n",
    "\n",
    "train_img_count = len([f for f in os.listdir(train_images) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "train_label_count = len([f for f in os.listdir(train_labels) if f.endswith('.txt')])\n",
    "valid_img_count = len([f for f in os.listdir(valid_images) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "valid_label_count = len([f for f in os.listdir(valid_labels) if f.endswith('.txt')])\n",
    "\n",
    "print(f\"tain:\")\n",
    "print(f\"  - Images: {train_img_count}\")\n",
    "print(f\"  - Labels: {train_label_count}\")\n",
    "print(f\"\\nvalidation\")\n",
    "print(f\"  - Images: {valid_img_count}\")\n",
    "print(f\"  - Labels: {valid_label_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d72f00d",
   "metadata": {},
   "source": [
    "## 7. Vérifier la correspondance images-labels et nettoyer les données\n",
    "\n",
    "- Vérifier que chaque image possède un label correspondant\n",
    "- Supprimer les images sans label\n",
    "- Supprimer les labels sans image correspondante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e872f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "datasets = {\n",
    "    'train': {\n",
    "        'images': 'filtered_data/train/images/',\n",
    "        'labels': 'filtered_data/train/labels/'\n",
    "    },\n",
    "    'valid': {\n",
    "        'images': 'filtered_data/valid/images/',\n",
    "        'labels': 'filtered_data/valid/labels/'\n",
    "    },\n",
    "    'test': {\n",
    "        'images': 'filtered_data/test/images/',\n",
    "        'labels': 'filtered_data/test/labels/'\n",
    "    }\n",
    "}\n",
    "\n",
    "def verify_and_clean(images_dir, labels_dir):\n",
    "    if not os.path.exists(images_dir) or not os.path.exists(labels_dir):\n",
    "        print(f\"Les répertoires {images_dir} ou {labels_dir} n'existent pas.\")\n",
    "        return\n",
    "    \n",
    "    images = {os.path.splitext(f)[0]: f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.png', '.jpeg'))}\n",
    "    labels = {os.path.splitext(f)[0]: f for f in os.listdir(labels_dir) if f.endswith('.txt')}\n",
    "    \n",
    "    images_removed = 0\n",
    "    labels_removed = 0\n",
    "    \n",
    "    for img_name in list(images.keys()):\n",
    "        if img_name not in labels:\n",
    "            os.remove(os.path.join(images_dir, images[img_name]))\n",
    "            images_removed += 1\n",
    "            print(f\"Image supprimée (pas de label): {images[img_name]}\")\n",
    "    \n",
    "    for label_name in list(labels.keys()):\n",
    "        if label_name not in images:\n",
    "            os.remove(os.path.join(labels_dir, labels[label_name]))\n",
    "            labels_removed += 1\n",
    "            print(f\"Label supprimé (pas d'image): {labels[label_name]}\")\n",
    "    \n",
    "    remaining_count = len(images) - images_removed\n",
    "    print(f\"\\nRésumé: {images_removed} images et {labels_removed} labels supprimés\")\n",
    "    print(f\"Paires valides restantes: {remaining_count}\\n\")\n",
    "\n",
    "for dataset_name, paths in datasets.items():\n",
    "    print(f\"=== Vérification de {dataset_name} ===\")\n",
    "    verify_and_clean(paths['images'], paths['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec62c68",
   "metadata": {},
   "source": [
    "## 8. Entraîner le modèle YOLOv8\n",
    "\n",
    "Lancer l'entraînement du modèle YOLO en définissant les hyperparamètres appropriés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8s.pt') \n",
    "\n",
    "model.train(\n",
    "    data='data.yaml',      \n",
    "    epochs=100,             \n",
    "    batch=-1,\n",
    "    cos_lr = True,\n",
    "    patience = 10,                       \n",
    "    device=0,    \n",
    "    save=True              \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d4e595",
   "metadata": {},
   "source": [
    "## 9. Évaluer et tester le modèle\n",
    "\n",
    "Évaluer et tester le modèle après l'entraînement pour mesurer :\n",
    "- Les performances\n",
    "- La précision\n",
    "- La capacité à généraliser sur des données inédites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46507ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54c968dc",
   "metadata": {},
   "source": [
    "## 10. Sauvegarder le modèle entraîné\n",
    "\n",
    "Sauvegarder le modèle entraîné pour une utilisation future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598a42c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
